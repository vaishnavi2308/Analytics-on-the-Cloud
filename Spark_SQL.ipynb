{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataframe assignment</h1>\n",
    "In this assignment, you need to write a user defined aggregate function that returns the mean and the standard deviation of a column in a dataframe. Your function should have the following characteristics:\n",
    "<ol>\n",
    "    <li>name the function <b>meanstd</b></li>\n",
    "    <li>meanstd should take three columns in the input schema</li>\n",
    "    <li>meanstd should contain a predicate function that takes two String arguments and returns true or false. The predicate function will serve as the \"selection criterion\" for including data in the mean and std deviation calculation\n",
    "    <li>data from the first two columns in the input schema will be the input values to the predicate function. If the predicate function returns true for a data row, then the third column value for that row will be included in the calculation of mean and std. If the predicate function returns false, that row will be skipped in the calculation</li>\n",
    "    <li>the predicate function should be replacable. I.e., you should be able to change the condition for different calls to meanstd</li>\n",
    "    <li>you need to calculate the mean and the std in one pass. Use the algorithm below</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Example</h1>\n",
    "\n",
    "Consider the following data table\n",
    "<table>\n",
    "    <tr><td>col1</td><td>col2</td><td>col3</td></tr>\n",
    "<tr><td>John</td><td>Cloud</td><td>9</td></tr>\n",
    "<tr><td>John</td><td>Analytics</td><td>7</td></tr>\n",
    "<tr><td>Jill</td><td>Cloud</td><td>8</td></tr>\n",
    "<tr><td>James</td><td>Analytics</td><td>11</td></tr>\n",
    "<tr><td>Jacinta</td><td>Politics</td><td>8</td></tr>\n",
    "<tr><td>Jacques</td><td>Cloud</td><td>9</td></tr>\n",
    "    </table> \n",
    "    \n",
    "\n",
    "\n",
    "A call to \n",
    "\n",
    "df.agg(meanstd(df(\"col1\"),df(\"col2\"),df(\"col3\"))) \n",
    "\n",
    "should return a mean of 8.8 and a standard deviation of 1.326 when the data selection condition is that the name of the student (col1) should start with the letter \"J\" and the quiz (col2) should be in either Cloud or Analytics.\n",
    "\n",
    "A call to \n",
    "\n",
    "df.groupBy(\"col2\").agg(meanstd(df(\"col1\"),df(\"col2\"),df(\"col3\"))) \n",
    "\n",
    "with the same condition should return:\n",
    "\n",
    "<pre>\n",
    "+---------+-----------------+\n",
    "|     col2|             mean|\n",
    "+---------+-----------------+\n",
    "|Analytics|              9.0|\n",
    "|    Cloud|8.666666666666666|\n",
    "| Politics|              NaN|\n",
    "+---------+-----------------+\n",
    "\n",
    "+---------+------------------+\n",
    "|     col2|               std|\n",
    "+---------+------------------+\n",
    "|Analytics|               2.0|\n",
    "|    Cloud|0.4714045207910384|\n",
    "| Politics|               NaN|\n",
    "+---------+------------------+\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deliverables</h1>\n",
    "<ol>\n",
    "    <li>The definition of meanstd (see the class outline below). Note that we can't use object here because we need to update the predicate function for each use. Note also that class instances are instantiated with new.</li>\n",
    "    <li>use meanstd to get the mean and standard deviation for the fare_amount field in taxi_data.csv</li>\n",
    "    <li>use meanstd to get the mean and standard deviation for the fare_amount field in taxi_data.csv for all trips that start and end in the same location zone (pickup location id is the same as dropoff location id)</li>\n",
    "    <li>use meanstd to get the mean and standard deviation for the fare_amount field in taxi_data.csv for all trips that start and end in the same location zone (pickup location id is the same as dropoff location id grouped by pickup location id</li>\n",
    "    <li>report the location id for the location with the highest mean from deliverable 4 above</li>\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>One pass algorithm for the mean and standard deviation</h2>\n",
    "<pre>\n",
    "    if(n == 0)\n",
    "        return 0.0;\n",
    "    sum = 0;\n",
    "    sq_sum = 0;\n",
    "    for(int i = 0; i < n; ++i) {\n",
    "       sum += a[i];\n",
    "       sq_sum += a[i] * a[i];\n",
    "    }\n",
    "    mean = sum / n;\n",
    "    stdev = sqrt(sq_sum / n - mean * mean);\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{Row, SparkSession}\r\n",
       "import org.apache.spark.sql.expressions.MutableAggregationBuffer\r\n",
       "import org.apache.spark.sql.expressions.UserDefinedAggregateFunction\r\n",
       "import org.apache.spark.sql.types._\r\n",
       "defined class meanstd\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "import org.apache.spark.sql.expressions.MutableAggregationBuffer\n",
    "import org.apache.spark.sql.expressions.UserDefinedAggregateFunction\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "class meanstd(p: (String,String) => Boolean) extends UserDefinedAggregateFunction {\n",
    "    def inputSchema: StructType = StructType(StructField(\"inputColumn1\", StringType) :: StructField(\"inputColumn2\", StringType) \n",
    "                                             :: StructField(\"inputColumn3\", DoubleType) :: Nil)\n",
    "    \n",
    "    def predicate(x:String, y: String):Boolean = {\n",
    "        if (p(x,y)) true\n",
    "        else false\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def bufferSchema: StructType = {\n",
    "        StructType(StructField(\"sum\", DoubleType) :: StructField(\"sq_sum\", DoubleType) :: StructField(\"count\", LongType) :: Nil)\n",
    "     }\n",
    "    \n",
    " \n",
    "    def dataType: DataType = {StructType(StructField(\"mean\",DoubleType) :: StructField(\"std\",DoubleType) :: Nil)}\n",
    "    \n",
    "    def deterministic: Boolean = true\n",
    "    \n",
    "    def initialize(buffer: MutableAggregationBuffer): Unit = {\n",
    "        buffer(0) = 0.0\n",
    "        buffer(1) = 0.0\n",
    "        buffer(2) = 0L\n",
    "    }\n",
    "    \n",
    "    def update(buffer: MutableAggregationBuffer, input: Row): Unit = {\n",
    "        if (!input.isNullAt(0) && !input.isNullAt(1) && !input.isNullAt(2)) {           \n",
    "            if (predicate(input.getString(0), input.getString(1))) {\n",
    "                buffer(0) = buffer.getDouble(0) + input.getDouble(2)\n",
    "                buffer(1) = buffer.getDouble(1) + input.getDouble(2)*input.getDouble(2)\n",
    "                buffer(2) = buffer.getLong(2) + 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    def merge(buffer1: MutableAggregationBuffer, buffer2: Row): Unit = {\n",
    "        buffer1(0) = buffer1.getDouble(0) + buffer2.getDouble(0)\n",
    "        buffer1(1) = buffer1.getDouble(1) + buffer2.getDouble(1)\n",
    "        buffer1(2) = buffer1.getLong(2) + buffer2.getLong(2)\n",
    "    }\n",
    "    \n",
    "     def evaluate(buffer: Row) = {\n",
    "         val mean = buffer.getDouble(0) / buffer.getLong(2) \n",
    "         val std = scala.math.sqrt((buffer.getDouble(1) / buffer.getLong(2)) - ((buffer.getDouble(0) / buffer.getLong(2))*(buffer.getDouble(0) / buffer.getLong(2))))\n",
    "         (mean, std)\n",
    "    }                                                    \n",
    "}\n",
    "\n",
    "//the default value of p\n",
    "//For each p, you will need to create a new instance of meanstd and update the register accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Unconditional mean and std</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "taxi: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 15 more fields]\r\n",
       "taxi_double: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 15 more fields]\r\n",
       "meanstd_uc: meanstd = meanstd@7e356894\r\n",
       "res4: org.apache.spark.sql.expressions.UserDefinedAggregateFunction = meanstd@7e356894\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val taxi = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"C://Users//vaish//Downloads//taxi_data.csv\")\n",
    "val taxi_double = taxi.withColumn(\"fare_amount\", taxi(\"fare_amount\").cast(DoubleType))\n",
    "val meanstd_uc = new meanstd((a,b) => true)\n",
    "spark.udf.register(\"meanstd_uc\", meanstd_uc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanstd_uc_df: org.apache.spark.sql.DataFrame = [meanstd(PULocationID, DOLocationID, fare_amount): struct<mean: double, std: double>]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val meanstd_uc_df = taxi_double.agg(meanstd_uc(taxi_double(\"PULocationID\"), taxi_double(\"DOLocationID\"), taxi_double(\"fare_amount\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              mean|\n",
      "+------------------+\n",
      "|12.404401066500117|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|               std|\n",
      "+------------------+\n",
      "|225.19866345385836|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanstd_uc_df.select($\"meanstd(PULocationID, DOLocationID, fare_amount).mean\").show()\n",
    "meanstd_uc_df.select($\"meanstd(PULocationID, DOLocationID, fare_amount).std\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>the mean is 12.404401066500117, the std is 225.19866345385836</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conditional mean and std</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanstd_cond: meanstd = meanstd@61a4d858\r\n",
       "meanstd_cond_df: org.apache.spark.sql.DataFrame = [meanstd(PULocationID, DOLocationID, fare_amount): struct<mean: double, std: double>]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val meanstd_cond = new meanstd((a,b) => if (a==b)true else false)\n",
    "spark.udf.register(\"meanstd_cond\", meanstd_cond)\n",
    "val meanstd_cond_df = taxi_double.agg(meanstd_cond(taxi_double(\"PULocationID\"), taxi_double(\"DOLocationID\"), taxi_double(\"fare_amount\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanstd_cond_df: org.apache.spark.sql.DataFrame = [meanstd(PULocationID, DOLocationID, fare_amount): struct<mean: double, std: double>]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val meanstd_cond_df = taxi_double.agg(meanstd_cond(taxi_double(\"PULocationID\"), taxi_double(\"DOLocationID\"), taxi_double(\"fare_amount\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             mean|\n",
      "+-----------------+\n",
      "|8.203262706753465|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|              std|\n",
      "+-----------------+\n",
      "|18.67995256537117|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanstd_cond_df.select($\"meanstd(PULocationID, DOLocationID, fare_amount).mean\").show()\n",
    "meanstd_cond_df.select($\"meanstd(PULocationID, DOLocationID, fare_amount).std\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>the mean is 8.203262706753465, the std is 18.67995256537117</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Grouped mean and std</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|PULocationID|              mean|\n",
      "+------------+------------------+\n",
      "|         125| 9.023267326732674|\n",
      "|           7| 6.142718658892129|\n",
      "|          51|15.236170212765956|\n",
      "|         124|24.608571428571427|\n",
      "|         169|14.773611111111112|\n",
      "|         205|30.300000000000004|\n",
      "|         234| 5.923206497093623|\n",
      "|         232| 9.423110403397027|\n",
      "|          54|11.783170731707317|\n",
      "|          15|            22.685|\n",
      "|         155|30.257741935483875|\n",
      "|         132|24.806696083838936|\n",
      "|         154|              15.7|\n",
      "|         200|16.532222222222224|\n",
      "|         101| 17.73076923076923|\n",
      "|          11|              43.3|\n",
      "|         138|14.307208465303773|\n",
      "|          69|10.537942857142857|\n",
      "|          29|24.921756097560976|\n",
      "|          42| 6.432658066860465|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+------------------+\n",
      "|PULocationID|               std|\n",
      "+------------+------------------+\n",
      "|         125| 13.79772025205827|\n",
      "|           7|  8.65121908948434|\n",
      "|          51|16.833672252451112|\n",
      "|         124|  23.9898951516624|\n",
      "|         169| 37.62075001118825|\n",
      "|         205|18.338094619826617|\n",
      "|         234| 6.962873088079954|\n",
      "|         232|16.397087974420632|\n",
      "|          54|11.530513588084313|\n",
      "|          15|19.781277638211343|\n",
      "|         155| 41.94394290614615|\n",
      "|         132|26.540284008686577|\n",
      "|         154|16.213985732488275|\n",
      "|         200|23.959431999285687|\n",
      "|         101|26.619191590781746|\n",
      "|          11| 86.09201753862531|\n",
      "|         138| 20.25620691888268|\n",
      "|          69|19.082592914475537|\n",
      "|          29| 67.15493047906331|\n",
      "|          42| 7.914748505013701|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "meanstd_grouped_df: org.apache.spark.sql.DataFrame = [PULocationID: string, meanstd(PULocationID, DOLocationID, fare_amount): struct<mean: double, std: double>]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val meanstd_grouped_df = taxi_double.groupBy(\"PULocationID\").agg(meanstd_cond(taxi_double(\"PULocationID\"), taxi_double(\"DOLocationID\"), taxi_double(\"fare_amount\")))\n",
    "meanstd_grouped_df.select($\"PULocationID\",$\"meanstd(PULocationID, DOLocationID, fare_amount).mean\").show()\n",
    "meanstd_grouped_df.select($\"PULocationID\", $\"meanstd(PULocationID, DOLocationID, fare_amount).std\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Highest mean location id</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest_mean_df: org.apache.spark.sql.DataFrame = [PULocationID: string, mean: double]\r\n",
       "highest_std_df: org.apache.spark.sql.DataFrame = [PULocationID: string, std: double]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val highest_mean_df = meanstd_grouped_df.select($\"PULocationID\",$\"meanstd(PULocationID, DOLocationID, fare_amount).mean\")\n",
    "val highest_std_df = meanstd_grouped_df.select($\"PULocationID\", $\"meanstd(PULocationID, DOLocationID, fare_amount).std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest_mean: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [PULocationID: string, mean: double]\r\n",
       "highest_std: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [PULocationID: string, std: double]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val highest_mean = highest_mean_df.orderBy(desc(\"mean\"))\n",
    "val highest_std = highest_std_df.orderBy(desc(\"std\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|PULocationID|              mean|\n",
      "+------------+------------------+\n",
      "|           1| 73.59195372750645|\n",
      "|         172|              72.4|\n",
      "|          84|             71.56|\n",
      "|         265| 68.54885736294776|\n",
      "|         251|60.592000000000006|\n",
      "|          46|              52.0|\n",
      "|         118|              51.0|\n",
      "|         204|             47.71|\n",
      "|         214|44.720909090909096|\n",
      "|          59|              43.5|\n",
      "|          11|              43.3|\n",
      "|         201| 40.25454545454546|\n",
      "|         117|          38.57875|\n",
      "|          31|             38.25|\n",
      "|         203| 37.50411764705882|\n",
      "|         245|           36.5425|\n",
      "|         175| 35.62307692307692|\n",
      "|          58|             34.68|\n",
      "|           5|             33.75|\n",
      "|         122| 33.36666666666667|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highest_mean.na.drop.show()\n",
    "//highest_std.na.drop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>so the highest mean location id is 1, the highest mean is 73.59195372750645</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|mean|\n",
      "+----+\n",
      "| 8.8|\n",
      "+----+\n",
      "\n",
      "+------------------+\n",
      "|               std|\n",
      "+------------------+\n",
      "|1.3266499161421565|\n",
      "+------------------+\n",
      "\n",
      "+---------+-----------------+\n",
      "|     col2|             mean|\n",
      "+---------+-----------------+\n",
      "|Analytics|              9.0|\n",
      "|    Cloud|8.666666666666666|\n",
      "| Politics|              NaN|\n",
      "+---------+-----------------+\n",
      "\n",
      "+---------+------------------+\n",
      "|     col2|               std|\n",
      "+---------+------------------+\n",
      "|Analytics|               2.0|\n",
      "|    Cloud|0.4714045207910384|\n",
      "| Politics|               NaN|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [col1: string, col2: string ... 1 more field]\r\n",
       "testdata: meanstd = meanstd@886a14\r\n",
       "testresult: org.apache.spark.sql.DataFrame = [col2: string, meanstd(col1, col2, col3): struct<mean: double, std: double>]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"C://Users//vaish//Downloads//test_data.csv\")\n",
    "var testdata = new meanstd((a,b) => {if (a.startsWith(\"J\") && (b == \"Cloud\" | b == \"Analytics\")) true else false})\n",
    "spark.udf.register(\"testdata\", testdata)\n",
    "\n",
    "df.agg(testdata(df(\"col1\"),df(\"col2\"),df(\"col3\"))).select(\"meanstd(col1, col2, col3).mean\").show\n",
    "df.agg(testdata(df(\"col1\"),df(\"col2\"),df(\"col3\"))).select(\"meanstd(col1, col2, col3).std\").show\n",
    "\n",
    "val testresult = df.groupBy(\"col2\").agg(testdata(df(\"col1\"),df(\"col2\"),df(\"col3\")))\n",
    "testresult.select($\"col2\",$\"meanstd(col1, col2, col3).mean\").show\n",
    "testresult.select($\"col2\",$\"meanstd(col1, col2, col3).std\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
